{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster\n",
    "Overview From kaggle:  \n",
    "The data has been split into two groups:\n",
    "\n",
    "1. training set (train.csv)\n",
    "2. test set (test.csv)\n",
    "\n",
    "The training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use feature engineering to create new features.\n",
    "\n",
    "The test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
    "\n",
    "We also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\n",
    "\n",
    "| Variable | Definition                                  | Key                                            |\n",
    "| -------- | ------------------------------------------- | ---------------------------------------------- |\n",
    "| Survived | Survival                                    | 0 = No, 1 = Yes                                |\n",
    "| Pclass   | Ticket class                                | 1 = 1st, 2 = 2nd, 3 = 3rd                      |\n",
    "| Sex      | Sex                                         |                                                |\n",
    "| Age      | Age in years                                |                                                |\n",
    "| Sibsp    | \\# of siblings / spouses aboard the Titanic |                                                |\n",
    "| Parch    | \\# of parents / children aboard the Titanic |                                                |\n",
    "| Ticket   | Ticket number                               |                                                |\n",
    "| Fare     | Passenger fare                              |                                                |\n",
    "| Cabin    | Cabin number                                |                                                |\n",
    "| Embarked | Port of Embarkation                         | C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "Variable Notes\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5  \n",
    "\n",
    "sibsp: The dataset defines family relations in this way...  \n",
    "Sibling = brother, sister, stepbrother, stepsister  \n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)  \n",
    "\n",
    "parch: The dataset defines family relations in this way...  \n",
    "Parent = mother, father  \n",
    "Child = daughter, son, stepdaughter, stepson  \n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the data\n",
    "I will be using a subset of the training data to test before finilizing the model. The original testing dataset will be called submit. The finilized model will use the full training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.read_csv('./train.csv')\n",
    "submit = pd.read_csv('./test.csv')\n",
    "\n",
    "submit['submit'] = True\n",
    "submit['Survived'] = -1\n",
    "train_full['submit'] = False\n",
    "data = pd.concat([submit, train_full], copy=True)\n",
    "del submit, train_full\n",
    "\n",
    "data['Survived'] = data['Survived'].astype(int)\n",
    "data['Embarked'] = data['Embarked'].map({'S':0, 'C':1, 'Q':2})\n",
    "data['Sex'] = data['Sex'].map( {'male':1, 'female':0} )\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will set the single NA fare to the average Fare and the 2 NA embarked values to the most common location Southhampton or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare'].fillna(np.average(data[data['Fare'].notnull()]['Fare']), inplace=True)\n",
    "data['Embarked'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the Age values are missing. I will use a linear model to predict age for each of the missing values. Like the original dataset, predicted ages will be of the format XX.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "age_train_x = data.drop(['Name', 'Ticket', 'Cabin', 'submit'], axis=1).dropna().drop('Age', axis=1)\n",
    "age_train_y = data['Age'].dropna()\n",
    "\n",
    "age_mod = lm.LinearRegression()\n",
    "age_mod.fit(age_train_x, age_train_y)\n",
    "\n",
    "age_na = data[data['Age'].isna()].copy()\n",
    "age_na_x = age_na.drop(['Name', 'Ticket', 'Cabin', 'submit', 'Age'], axis=1)\n",
    "\n",
    "# round and make end in 0.5\n",
    "age_na['Age'] = np.subtract(np.add(age_mod.predict(age_na_x),0.5).round(),0.5)\n",
    "age_na[age_na['Age'] < 0]['Age'] = 0.5\n",
    "data[data['Age'].isna()] = age_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Some More Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data['Prefix'] = data['Name'].apply(lambda s: s.split(', ')[1].split('. ')[0]).map(\n",
    "    {'Mr':0,\n",
    "    'Miss':1,\n",
    "    'Mrs':2,\n",
    "    'Master':3,\n",
    "    'Rev':4,\n",
    "    'Dr':5,\n",
    "    'Col':6,\n",
    "    'Ms':7,\n",
    "    'Major':8,\n",
    "    'Mlle':9,\n",
    "    'Sir':9,\n",
    "    'the Countess':9,\n",
    "    'Capt':9,\n",
    "    'Don':9,\n",
    "    'Lady':9,\n",
    "    'Mme':9,\n",
    "    'Dona':9,\n",
    "    'Jonkheer':9})\n",
    "data['Prefix'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_full = data[data['submit'] == False].drop('submit', axis=1)\n",
    "train, test = train_test_split(train_full)\n",
    "submit = data[data['submit'] == True].drop(['submit'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], axis=1)\n",
    "train_y = train['Survived']\n",
    "\n",
    "train_full_x = train_full.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], axis=1)\n",
    "train_full_y = train_full['Survived']\n",
    "\n",
    "submit_x = submit.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], axis=1)\n",
    "predictions = submit[['PassengerId', 'Survived']].copy()\n",
    "\n",
    "test_x = test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], axis=1)\n",
    "test_y = test['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "mod_svc = svm.SVC()\n",
    "mod_svc.fit(train_x, train_y)\n",
    "\n",
    "print(classification_report(test_y, mod_svc.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_log = lm.LogisticRegression(max_iter=1000)\n",
    "mod_log.fit(train_x, train_y)\n",
    "\n",
    "print(classification_report(test_y, mod_log.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive Agressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_pag = lm.PassiveAggressiveClassifier()\n",
    "mod_pag.fit(train_x, train_y)\n",
    "\n",
    "print(classification_report(test_y, mod_pag.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "mod_dec = tree.DecisionTreeClassifier()\n",
    "mod_dec.fit(train_x, train_y)\n",
    "\n",
    "print(classification_report(test_y, mod_dec.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "mod_gnb = naive_bayes.GaussianNB()\n",
    "mod_gnb.fit(train_x, train_y)\n",
    "\n",
    "print(classification_report(test_y, mod_gnb.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "mod_rfo = ensemble.RandomForestClassifier(n_estimators=1000)\n",
    "mod_rfo.fit(train_x, train_y)\n",
    "\n",
    "print(classification_report(test_y, mod_rfo.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_gbc = ensemble.GradientBoostingClassifier(n_estimators=500)\n",
    "mod_gbc.fit(train_x, train_y)\n",
    "print(classification_report(test_y, mod_gbc.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_ada = ensemble.AdaBoostClassifier(n_estimators=50)\n",
    "mod_ada.fit(train_x, train_y)\n",
    "print(classification_report(test_y, mod_ada.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Best Model  \n",
    "Which appears to be gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection as ms\n",
    "\n",
    "parameters = {\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05],\n",
    "    \"n_estimators\":list(range(400,625,25))\n",
    "    }\n",
    "\n",
    "\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "gscv_gbc = ms.GridSearchCV(gbc, parameters, cv=5, n_jobs=-1, verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_gbc.fit(train_x, train_y)\n",
    "print(classification_report(test_y, gscv_gbc.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame.from_dict(gscv_gbc.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_gbc = ms.GridSearchCV(gbc, parameters, cv=10, n_jobs=-1, verbose=4)\n",
    "gscv_gbc.fit(train_full_x, train_full_y)\n",
    "predictions['Survived'] = gscv_gbc.predict(submit_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputting Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions\n",
    "predictions.to_csv('./final_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "892ebd4069c476ef2519eb08fc34f09773c6d31fe7adf021a4464fdd785e030a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
